{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-probability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NASNetLarge 불러오기\n",
    "\n",
    "from tensorflow.keras.applications import NASNetLarge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from math import cos, sin, pi\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Activation, Convolution2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout, Conv2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.applications import InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-austria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 이동\n",
    "os.chdir(os.getenv('HOME') + '/1.AIFFEL_Study/Competition/1.motion_keypoint/0.data/1. open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-collect",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-equipment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터 중 10%를 검증 데이터로 사용\n",
    "\n",
    "# csv 파일 불러오기\n",
    "data = pd.read_csv('train_df.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# 경로 설정\n",
    "data_paths = sorted(glob.glob('./train_imgs/*.jpg'))\n",
    "test_paths = sorted(glob.glob('./test_imgs/*.jpg'))\n",
    "\n",
    "data['path'] = data_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-liabilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 프레임 랜덤하게 분할\n",
    "\n",
    "# 전체 데이터 중 90%는 학습 데이터 활용\n",
    "train = data.sample(frac=0.9, random_state=2021)\n",
    "print('학습 데이터 길이는: ', len(train))\n",
    "\n",
    "# 전체 데이터 중 10%는 검증 데이터 활용\n",
    "valid = data.drop(train.index)\n",
    "print('검증 데이터 길이는: ', len(valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-sheriff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 좌우 반전\n",
    "def left_right_flip(images, keypoints):\n",
    "    flipped_keypoints = []\n",
    "    flipped_images = np.flip(images, axis=1)\n",
    "    for idx, sample_keypoints in enumerate(keypoints):\n",
    "        if idx%2 == 0:\n",
    "            flipped_keypoints.append(331.-sample_keypoints)\n",
    "        else:\n",
    "            flipped_keypoints.append(sample_keypoints)\n",
    "    \n",
    "    # left_right_keypoints_convert\n",
    "    for i in range(8):\n",
    "        flipped_keypoints[2+(4*i):4+(4*i)], flipped_keypoints[4+(4*i):6+(4*i)] = flipped_keypoints[4+(4*i):6+(4*i)], flipped_keypoints[2+(4*i):4+(4*i)]\n",
    "    flipped_keypoints[36:38], flipped_keypoints[38:40] = flipped_keypoints[38:40], flipped_keypoints[36:38]\n",
    "    flipped_keypoints[44:46], flipped_keypoints[46:48] = flipped_keypoints[46:48], flipped_keypoints[44:46]\n",
    "    \n",
    "    return flipped_images, flipped_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-gothic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation Setting\n",
    "pixel_shifts = [12]\n",
    "rotation_angles = [12]\n",
    "inc_brightness_ratio = 1.2\n",
    "dec_brightness_ratio = 0.8\n",
    "noise_ratio = 0.008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-category",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수직/수평 동시 이동\n",
    "# forloop에서 shift_x, shift_y 중 하나만 놓으면\n",
    "# 수직 또는 수평 이동만 따로 시행 가능\n",
    "def shift_images(images, keypoints):\n",
    "    # tensor -> numpy\n",
    "    images = images.numpy()\n",
    "    shifted_images = []\n",
    "    shifted_keypoints = []\n",
    "    for shift in pixel_shifts:   \n",
    "        for (shift_x,shift_y) in [(-shift,-shift),(-shift,shift),(shift,-shift),(shift,shift)]:\n",
    "            # 이동할 matrix 생성\n",
    "            M = np.float32([[1,0,shift_x],[0,1,shift_y]])\n",
    "            shifted_keypoint = np.array([])\n",
    "            shifted_x_list = np.array([])\n",
    "            shifted_y_list = np.array([])\n",
    "            # 이미지 이동\n",
    "            shifted_image = cv2.warpAffine(images, M, (331,331), flags=cv2.INTER_CUBIC)\n",
    "            # 이동한만큼 keypoint 수정\n",
    "            for idx, point in enumerate(keypoints):\n",
    "                if idx%2 == 0: \n",
    "                    shifted_keypoint = np.append(shifted_keypoint, point+shift_x)\n",
    "                    shifted_x_list = np.append(shifted_x_list, point+shift_x)\n",
    "                else: \n",
    "                    shifted_keypoint =np.append(shifted_keypoint, point+shift_y)\n",
    "                    shifted_y_list = np.append(shifted_y_list, point+shift_y)\n",
    "            # 수정된 keypoint가 이미지 사이즈를 벗어나지 않으면 append\n",
    "            if np.all(0.0<shifted_x_list) and np.all(shifted_x_list<331) and np.all(0.0<shifted_y_list) and np.all(shifted_y_list<331):\n",
    "                shifted_images.append(shifted_image.reshape(331,331,3))\n",
    "                shifted_keypoints.append(shifted_keypoint)\n",
    "\n",
    "    return shifted_images, shifted_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-syndrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 회전\n",
    "def rotate_augmentation(images, keypoints):\n",
    "    # tensor -> numpy\n",
    "    images = images.numpy()\n",
    "    rotated_images = []\n",
    "    rotated_keypoints = []\n",
    "    \n",
    "    for angle in rotation_angles:\n",
    "        for angle in [angle,-angle]:\n",
    "            # 회전할 matrix 생성\n",
    "            M = cv2.getRotationMatrix2D((240,135), angle, 1.0)\n",
    "            # cv2_imshow로는 문제없지만 추후 plt.imshow로 사진을 확인할 경우 black screen 생성...\n",
    "            # 혹시 몰라 matrix를 ndarray로 변환\n",
    "            M = np.array(M, dtype=np.float32)\n",
    "            angle_rad = -angle*pi/180\n",
    "            rotated_image = cv2.warpAffine(images, M, (331,331))\n",
    "            rotated_images.append(rotated_image)\n",
    "            \n",
    "            # keypoint를 copy하여 forloop상에서 값이 계속 없데이트 되는 것을 회피\n",
    "            rotated_keypoint = keypoints.copy()\n",
    "            rotated_keypoint[0::2] = rotated_keypoint[0::2] - 240\n",
    "            rotated_keypoint[1::2] = rotated_keypoint[1::2] - 135\n",
    "            \n",
    "            for idx in range(0,len(rotated_keypoint),2):\n",
    "                rotated_keypoint[idx] = rotated_keypoint[idx]*cos(angle_rad)-rotated_keypoint[idx+1]*sin(angle_rad)\n",
    "                rotated_keypoint[idx+1] = rotated_keypoint[idx]*sin(angle_rad)+rotated_keypoint[idx+1]*cos(angle_rad)\n",
    "\n",
    "            rotated_keypoint[0::2] = rotated_keypoint[0::2] + 240\n",
    "            rotated_keypoint[1::2] = rotated_keypoint[1::2] + 135\n",
    "            rotated_keypoints.append(rotated_keypoint)\n",
    "        \n",
    "    return rotated_images, rotated_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-notification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 해상도 조절\n",
    "def alter_brightness(images):\n",
    "    altered_brightness_images = []\n",
    "    inc_brightness_images = np.clip(images*inc_brightness_ratio, 0.0, 1.0)\n",
    "    dec_brightness_images = np.clip(images*dec_brightness_ratio, 0.0, 1.0)\n",
    "    altered_brightness_images.append(inc_brightness_images)\n",
    "    altered_brightness_images.append(dec_brightness_images)\n",
    "    return altered_brightness_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-guide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random 노이즈 추가\n",
    "def add_noise(images):\n",
    "    images = images.numpy()\n",
    "    noise = noise_ratio * np.random.randn(331,331,3)\n",
    "    noise = noise.astype(np.float32)\n",
    "    # 생성한 noise를 원본에 add\n",
    "    noisy_image = cv2.add(images, noise)\n",
    "    return noisy_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-introduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainGenerator():\n",
    "    # 원본 이미지 resize\n",
    "    for i in range(len(train)):\n",
    "        img = tf.io.read_file(train['path'][i]) # path(경로)를 통해 이미지 읽기\n",
    "        img = tf.image.decode_jpeg(img, channels=3) # 경로를 통해 불러온 이미지를 tensor로 변환\n",
    "        img = tf.image.resize(img, [331,331]) # 이미지 resize \n",
    "        img = img/255                         # 이미지 rescaling\n",
    "        target = train.iloc[:,1:49].iloc[i,:] # keypoint 뽑아주기\n",
    "        target = target/4                     # image size를 1920x1080 -> 480x270으로 바꿔줬으므로 keypoint도 변경\n",
    "\n",
    "        yield (img, target)\n",
    "    \n",
    "    # horizontal flip\n",
    "#     for i in range(len(train)):\n",
    "#         img = tf.io.read_file(train['path'][i]) \n",
    "#         img = tf.image.decode_jpeg(img, channels=3) \n",
    "#         img = tf.image.resize(img, [331,331]) \n",
    "#         img = img/255\n",
    "#         target = train.iloc[:,1:49].iloc[i,:] \n",
    "#         target = target/4\n",
    "#         img, target = left_right_flip(img, target)\n",
    "        \n",
    "#         yield (img, target)\n",
    "\n",
    "    # Horizontal & Vertical shift\n",
    "#     for i in range(len(train)):\n",
    "#         img = tf.io.read_file(train['path'][i])\n",
    "#         img = tf.image.decode_jpeg(img, channels=3)\n",
    "#         img = tf.image.resize(img, [331,331])\n",
    "#         img = img/255\n",
    "#         target = train.iloc[:,1:49].iloc[i,:]\n",
    "#         target = target/4\n",
    "#         img_list, target_list = shift_images(img, target)\n",
    "#         for shifted_img, shifted_target in zip(img_list, target_list):\n",
    "            \n",
    "#             yield (shifted_img, shifted_target)\n",
    "\n",
    "    # Rotation\n",
    "    for i in range(len(train)):\n",
    "        img = tf.io.read_file(train['path'][i])\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, [331,331])\n",
    "        img = img/255\n",
    "        target = train.iloc[:,1:49].iloc[i,:]\n",
    "        target = target/4\n",
    "        img_list, target_list = rotate_augmentation(img, target)\n",
    "        for rotated_img, rotated_target in zip(img_list, target_list):\n",
    "            \n",
    "            yield (rotated_img, rotated_target)\n",
    "\n",
    "    # Alter_Brightness\n",
    "    for i in range(len(train)):\n",
    "        img = tf.io.read_file(train['path'][i])\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, [331,331])\n",
    "        img = img/255\n",
    "        target = train.iloc[:,1:49].iloc[i,:]\n",
    "        target = target/4\n",
    "        img_list = alter_brightness(img)\n",
    "        for altered_brightness_images in img_list:\n",
    "            \n",
    "            yield (altered_brightness_images, target)\n",
    "\n",
    "    # Adding_Noise\n",
    "#     for i in range(len(train)):\n",
    "#         img = tf.io.read_file(train['path'][i])\n",
    "#         img = tf.image.decode_jpeg(img, channels=3)\n",
    "#         img = tf.image.resize(img, [331,331])\n",
    "#         img = img/255\n",
    "#         target = train.iloc[:,1:49].iloc[i,:]\n",
    "#         target = target/4\n",
    "#         noisy_img = add_noise(img)\n",
    "\n",
    "#         yield (noisy_img, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "batch_size = 2\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    trainGenerator, (tf.float32, tf.float32), (tf.TensorShape([331, 331, 3]), tf.TensorShape([48])))\n",
    "train_dataset = train_dataset.batch(batch_size).prefetch(AUTOTUNE)\n",
    "valid_dataset = tf.data.Dataset.from_generator(\n",
    "    trainGenerator, (tf.float32, tf.float32), (tf.TensorShape([331, 331, 3]), tf.TensorShape([48])))\n",
    "valid_dataset = valid_dataset.batch(batch_size).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-ready",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(drop=True, inplace=True)\n",
    "valid.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-explorer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback 설정\n",
    "early_stopping = EarlyStopping(patience=3)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=2,\n",
    "    factor=0.85,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(  # 에포크마다 현재 가중치를 저장\n",
    "    filepath=\"./model_checkpoint_callback_210322_{epoch}.h5\",  # 모델 파일 경로\n",
    "    monitor='val_loss',  # val_loss가 좋아지지 않으면 모델 파일을 덮어쓰지 않음.\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping, reduce_lr, model_checkpoint_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = NASNetLarge(input_shape=(\n",
    "    331, 331, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu', input_dim=(7*13*1536))(x)\n",
    "x = Dropout(0.1)(x)\n",
    "predictions = Dense(48)(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.01),\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-beverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-luxembourg",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=3,\n",
    "    validation_data=valid_dataset,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('model_NASLarge.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=[]\n",
    "\n",
    "for test_path in tqdm(test_paths):\n",
    "    img=tf.io.read_file(test_path)\n",
    "    img=tf.image.decode_jpeg(img, channels=3)\n",
    "    img=tf.image.resize(img, [331,331])\n",
    "    img=img/255\n",
    "    X_test.append(img)\n",
    "\n",
    "X_test=tf.stack(X_test, axis=0)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-source",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-present",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./sample_submission.csv')\n",
    "# image size를 1920x1080 -> 480x270으로 바꿔서 예측했으므로 * 4\n",
    "submission.iloc[:, 1:] = pred*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-marine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission\n",
    "submission.to_csv('submission_210322_TL_NAS.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

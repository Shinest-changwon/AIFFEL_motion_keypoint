{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from math import cos, sin, pi\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Activation, Convolution2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout, Conv2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 이동\n",
    "os.chdir('data/1. open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train.csv',\n",
       " 'train_imgs.zip',\n",
       " 'train_df.csv',\n",
       " '210325_aug_Xception_04_10.h5',\n",
       " 'train_imgs',\n",
       " '210325_aug_Xception_01_4.h5',\n",
       " '210326_aug_Xception_05_1.h5',\n",
       " '2_augmentation(8_epochs).csv',\n",
       " 'test_imgs',\n",
       " '3_transferlearning2.csv',\n",
       " '210325_aug_Xception_01_3.h5',\n",
       " 'sample_submission.csv',\n",
       " '210325_aug_Xception_03_1.h5',\n",
       " 'submission_210326_aug_Xception_valacc63%.csv',\n",
       " '210325_aug_Xception_03_2.h5',\n",
       " '3_transferlearning(7epochs).csv',\n",
       " '3_transferlearning1.csv',\n",
       " '210325_aug_Xception_02_2.h5',\n",
       " '3_transferlearning.csv',\n",
       " 'saved_model.pb',\n",
       " '210325_aug_Xception_01_7.h5',\n",
       " '210325_aug_Xception_02_1.h5',\n",
       " 'val',\n",
       " '210325_aug_Xception_01_1.h5',\n",
       " 'baseline_submission.csv',\n",
       " 'valid.csv',\n",
       " 'training.csv',\n",
       " 'submission_210325_aug_Xception_valacc55%.csv',\n",
       " 'assets',\n",
       " 'train',\n",
       " 'variables',\n",
       " '210325_aug_Xception_04_8.h5',\n",
       " 'test_imgs.zip',\n",
       " '210325_aug_Xception_01_2.h5']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터 중 10%를 검증 데이터로 사용\n",
    "\n",
    "# csv 파일 불러오기\n",
    "data = pd.read_csv('train_df.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# 경로 설정\n",
    "data_paths = sorted(glob.glob('./train_imgs/*.jpg'))\n",
    "test_paths = sorted(glob.glob('./test_imgs/*.jpg'))\n",
    "\n",
    "data['path'] = data_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 길이는:  3776\n",
      "검증 데이터 길이는:  419\n"
     ]
    }
   ],
   "source": [
    "# 데이터 프레임 랜덤하게 분할\n",
    "\n",
    "# 전체 데이터 중 90%는 학습 데이터 활용\n",
    "train = data.sample(frac=0.9, random_state=2021)\n",
    "print('학습 데이터 길이는: ', len(train))\n",
    "\n",
    "# 전체 데이터 중 10%는 검증 데이터 활용\n",
    "valid = data.drop(train.index)\n",
    "print('검증 데이터 길이는: ', len(valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>nose_x</th>\n",
       "      <th>nose_y</th>\n",
       "      <th>left_eye_x</th>\n",
       "      <th>left_eye_y</th>\n",
       "      <th>right_eye_x</th>\n",
       "      <th>right_eye_y</th>\n",
       "      <th>left_ear_x</th>\n",
       "      <th>left_ear_y</th>\n",
       "      <th>right_ear_x</th>\n",
       "      <th>...</th>\n",
       "      <th>right_palm_y</th>\n",
       "      <th>spine2(back)_x</th>\n",
       "      <th>spine2(back)_y</th>\n",
       "      <th>spine1(waist)_x</th>\n",
       "      <th>spine1(waist)_y</th>\n",
       "      <th>left_instep_x</th>\n",
       "      <th>left_instep_y</th>\n",
       "      <th>right_instep_x</th>\n",
       "      <th>right_instep_y</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>186-1-1-08-Z36_E-0000025.jpg</td>\n",
       "      <td>798.933008</td>\n",
       "      <td>373.245639</td>\n",
       "      <td>793.866015</td>\n",
       "      <td>359.459874</td>\n",
       "      <td>807.169574</td>\n",
       "      <td>357.482205</td>\n",
       "      <td>806.000000</td>\n",
       "      <td>355.000000</td>\n",
       "      <td>855.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>865.280391</td>\n",
       "      <td>460.337474</td>\n",
       "      <td>879.516120</td>\n",
       "      <td>535.617865</td>\n",
       "      <td>838.000000</td>\n",
       "      <td>913.000000</td>\n",
       "      <td>875.967760</td>\n",
       "      <td>903.528542</td>\n",
       "      <td>./train_imgs/186-1-1-08-Z36_E-0000025.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>474-1-2-21-Z134_A-0000009.jpg</td>\n",
       "      <td>1174.947912</td>\n",
       "      <td>639.230112</td>\n",
       "      <td>1174.871199</td>\n",
       "      <td>659.153408</td>\n",
       "      <td>1194.947920</td>\n",
       "      <td>650.871224</td>\n",
       "      <td>1144.282200</td>\n",
       "      <td>698.564400</td>\n",
       "      <td>1195.714959</td>\n",
       "      <td>...</td>\n",
       "      <td>579.956605</td>\n",
       "      <td>1037.861370</td>\n",
       "      <td>639.306809</td>\n",
       "      <td>959.634094</td>\n",
       "      <td>612.817037</td>\n",
       "      <td>706.561671</td>\n",
       "      <td>497.947990</td>\n",
       "      <td>732.270802</td>\n",
       "      <td>485.008540</td>\n",
       "      <td>./train_imgs/474-1-2-21-Z134_A-0000009.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001-1-1-01-Z17_C-0000013.jpg</td>\n",
       "      <td>953.109409</td>\n",
       "      <td>328.531353</td>\n",
       "      <td>954.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>933.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>969.312380</td>\n",
       "      <td>322.468647</td>\n",
       "      <td>921.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>355.359180</td>\n",
       "      <td>985.357813</td>\n",
       "      <td>451.768530</td>\n",
       "      <td>992.703545</td>\n",
       "      <td>514.421905</td>\n",
       "      <td>995.766173</td>\n",
       "      <td>876.202971</td>\n",
       "      <td>856.124302</td>\n",
       "      <td>750.687572</td>\n",
       "      <td>./train_imgs/001-1-1-01-Z17_C-0000013.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>282-2-1-14-Z57_A-0000021.jpg</td>\n",
       "      <td>966.449343</td>\n",
       "      <td>331.632895</td>\n",
       "      <td>959.572700</td>\n",
       "      <td>312.490462</td>\n",
       "      <td>972.000000</td>\n",
       "      <td>319.000000</td>\n",
       "      <td>938.895719</td>\n",
       "      <td>306.041119</td>\n",
       "      <td>955.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>589.367105</td>\n",
       "      <td>909.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>907.000000</td>\n",
       "      <td>514.000000</td>\n",
       "      <td>896.000000</td>\n",
       "      <td>856.000000</td>\n",
       "      <td>982.000000</td>\n",
       "      <td>874.000000</td>\n",
       "      <td>./train_imgs/282-2-1-14-Z57_A-0000021.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>642-2-4-31-Z148_D-0000011.jpg</td>\n",
       "      <td>852.178815</td>\n",
       "      <td>404.919392</td>\n",
       "      <td>863.435893</td>\n",
       "      <td>375.317445</td>\n",
       "      <td>830.081597</td>\n",
       "      <td>416.593408</td>\n",
       "      <td>846.341823</td>\n",
       "      <td>377.819042</td>\n",
       "      <td>873.442188</td>\n",
       "      <td>...</td>\n",
       "      <td>806.838679</td>\n",
       "      <td>1084.408063</td>\n",
       "      <td>592.954292</td>\n",
       "      <td>1205.317386</td>\n",
       "      <td>662.164418</td>\n",
       "      <td>1226.580743</td>\n",
       "      <td>878.550402</td>\n",
       "      <td>1215.323665</td>\n",
       "      <td>851.450037</td>\n",
       "      <td>./train_imgs/642-2-4-31-Z148_D-0000011.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3771</th>\n",
       "      <td>546-1-2-25-Z134_D-0000013.jpg</td>\n",
       "      <td>645.000000</td>\n",
       "      <td>586.000000</td>\n",
       "      <td>636.000000</td>\n",
       "      <td>591.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>596.000000</td>\n",
       "      <td>646.000000</td>\n",
       "      <td>620.000000</td>\n",
       "      <td>623.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>745.000000</td>\n",
       "      <td>711.615351</td>\n",
       "      <td>633.488674</td>\n",
       "      <td>814.195946</td>\n",
       "      <td>652.573006</td>\n",
       "      <td>1147.000000</td>\n",
       "      <td>745.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>814.000000</td>\n",
       "      <td>./train_imgs/546-1-2-25-Z134_D-0000013.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>186-1-1-08-Z36_E-0000023.jpg</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>590.000000</td>\n",
       "      <td>754.933008</td>\n",
       "      <td>578.325890</td>\n",
       "      <td>752.236567</td>\n",
       "      <td>579.325890</td>\n",
       "      <td>760.504536</td>\n",
       "      <td>566.223308</td>\n",
       "      <td>766.504536</td>\n",
       "      <td>...</td>\n",
       "      <td>526.370551</td>\n",
       "      <td>852.794836</td>\n",
       "      <td>543.696441</td>\n",
       "      <td>916.085136</td>\n",
       "      <td>578.089323</td>\n",
       "      <td>831.712212</td>\n",
       "      <td>909.426797</td>\n",
       "      <td>874.019819</td>\n",
       "      <td>902.101745</td>\n",
       "      <td>./train_imgs/186-1-1-08-Z36_E-0000023.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3773</th>\n",
       "      <td>282-2-1-14-Z57_A-0000017.jpg</td>\n",
       "      <td>1024.490462</td>\n",
       "      <td>546.000000</td>\n",
       "      <td>1027.756253</td>\n",
       "      <td>530.898686</td>\n",
       "      <td>1037.632895</td>\n",
       "      <td>543.325986</td>\n",
       "      <td>1025.756253</td>\n",
       "      <td>506.082238</td>\n",
       "      <td>1040.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>730.917762</td>\n",
       "      <td>939.000000</td>\n",
       "      <td>497.000000</td>\n",
       "      <td>882.000000</td>\n",
       "      <td>530.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>855.000000</td>\n",
       "      <td>983.000000</td>\n",
       "      <td>874.000000</td>\n",
       "      <td>./train_imgs/282-2-1-14-Z57_A-0000017.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3774</th>\n",
       "      <td>177-1-1-07-Z36_D-0000029.jpg</td>\n",
       "      <td>744.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>755.000000</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>735.000000</td>\n",
       "      <td>271.000000</td>\n",
       "      <td>798.000000</td>\n",
       "      <td>258.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>533.000000</td>\n",
       "      <td>813.000000</td>\n",
       "      <td>423.000000</td>\n",
       "      <td>807.772054</td>\n",
       "      <td>501.428767</td>\n",
       "      <td>833.000000</td>\n",
       "      <td>926.000000</td>\n",
       "      <td>797.000000</td>\n",
       "      <td>911.000000</td>\n",
       "      <td>./train_imgs/177-1-1-07-Z36_D-0000029.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3775</th>\n",
       "      <td>282-2-1-14-Z57_E-0000025.jpg</td>\n",
       "      <td>873.509538</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>856.000000</td>\n",
       "      <td>590.000000</td>\n",
       "      <td>866.693090</td>\n",
       "      <td>584.490462</td>\n",
       "      <td>856.000000</td>\n",
       "      <td>561.000000</td>\n",
       "      <td>871.427300</td>\n",
       "      <td>...</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>948.000000</td>\n",
       "      <td>525.000000</td>\n",
       "      <td>1016.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>915.000000</td>\n",
       "      <td>859.000000</td>\n",
       "      <td>1007.000000</td>\n",
       "      <td>842.000000</td>\n",
       "      <td>./train_imgs/282-2-1-14-Z57_E-0000025.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3776 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              image       nose_x      nose_y   left_eye_x  \\\n",
       "0      186-1-1-08-Z36_E-0000025.jpg   798.933008  373.245639   793.866015   \n",
       "1     474-1-2-21-Z134_A-0000009.jpg  1174.947912  639.230112  1174.871199   \n",
       "2      001-1-1-01-Z17_C-0000013.jpg   953.109409  328.531353   954.000000   \n",
       "3      282-2-1-14-Z57_A-0000021.jpg   966.449343  331.632895   959.572700   \n",
       "4     642-2-4-31-Z148_D-0000011.jpg   852.178815  404.919392   863.435893   \n",
       "...                             ...          ...         ...          ...   \n",
       "3771  546-1-2-25-Z134_D-0000013.jpg   645.000000  586.000000   636.000000   \n",
       "3772   186-1-1-08-Z36_E-0000023.jpg   767.000000  590.000000   754.933008   \n",
       "3773   282-2-1-14-Z57_A-0000017.jpg  1024.490462  546.000000  1027.756253   \n",
       "3774   177-1-1-07-Z36_D-0000029.jpg   744.000000  284.000000   755.000000   \n",
       "3775   282-2-1-14-Z57_E-0000025.jpg   873.509538  599.000000   856.000000   \n",
       "\n",
       "      left_eye_y  right_eye_x  right_eye_y   left_ear_x  left_ear_y  \\\n",
       "0     359.459874   807.169574   357.482205   806.000000  355.000000   \n",
       "1     659.153408  1194.947920   650.871224  1144.282200  698.564400   \n",
       "2     313.000000   933.000000   325.000000   969.312380  322.468647   \n",
       "3     312.490462   972.000000   319.000000   938.895719  306.041119   \n",
       "4     375.317445   830.081597   416.593408   846.341823  377.819042   \n",
       "...          ...          ...          ...          ...         ...   \n",
       "3771  591.000000   625.000000   596.000000   646.000000  620.000000   \n",
       "3772  578.325890   752.236567   579.325890   760.504536  566.223308   \n",
       "3773  530.898686  1037.632895   543.325986  1025.756253  506.082238   \n",
       "3774  264.000000   735.000000   271.000000   798.000000  258.000000   \n",
       "3775  590.000000   866.693090   584.490462   856.000000  561.000000   \n",
       "\n",
       "      right_ear_x  ...  right_palm_y  spine2(back)_x  spine2(back)_y  \\\n",
       "0      855.000000  ...    340.000000      865.280391      460.337474   \n",
       "1     1195.714959  ...    579.956605     1037.861370      639.306809   \n",
       "2      921.000000  ...    355.359180      985.357813      451.768530   \n",
       "3      955.000000  ...    589.367105      909.000000      448.000000   \n",
       "4      873.442188  ...    806.838679     1084.408063      592.954292   \n",
       "...           ...  ...           ...             ...             ...   \n",
       "3771   623.000000  ...    745.000000      711.615351      633.488674   \n",
       "3772   766.504536  ...    526.370551      852.794836      543.696441   \n",
       "3773  1040.000000  ...    730.917762      939.000000      497.000000   \n",
       "3774   800.000000  ...    533.000000      813.000000      423.000000   \n",
       "3775   871.427300  ...    768.000000      948.000000      525.000000   \n",
       "\n",
       "      spine1(waist)_x  spine1(waist)_y  left_instep_x  left_instep_y  \\\n",
       "0          879.516120       535.617865     838.000000     913.000000   \n",
       "1          959.634094       612.817037     706.561671     497.947990   \n",
       "2          992.703545       514.421905     995.766173     876.202971   \n",
       "3          907.000000       514.000000     896.000000     856.000000   \n",
       "4         1205.317386       662.164418    1226.580743     878.550402   \n",
       "...               ...              ...            ...            ...   \n",
       "3771       814.195946       652.573006    1147.000000     745.000000   \n",
       "3772       916.085136       578.089323     831.712212     909.426797   \n",
       "3773       882.000000       530.000000     898.000000     855.000000   \n",
       "3774       807.772054       501.428767     833.000000     926.000000   \n",
       "3775      1016.000000       524.000000     915.000000     859.000000   \n",
       "\n",
       "      right_instep_x  right_instep_y  \\\n",
       "0         875.967760      903.528542   \n",
       "1         732.270802      485.008540   \n",
       "2         856.124302      750.687572   \n",
       "3         982.000000      874.000000   \n",
       "4        1215.323665      851.450037   \n",
       "...              ...             ...   \n",
       "3771     1025.000000      814.000000   \n",
       "3772      874.019819      902.101745   \n",
       "3773      983.000000      874.000000   \n",
       "3774      797.000000      911.000000   \n",
       "3775     1007.000000      842.000000   \n",
       "\n",
       "                                            path  \n",
       "0      ./train_imgs/186-1-1-08-Z36_E-0000025.jpg  \n",
       "1     ./train_imgs/474-1-2-21-Z134_A-0000009.jpg  \n",
       "2      ./train_imgs/001-1-1-01-Z17_C-0000013.jpg  \n",
       "3      ./train_imgs/282-2-1-14-Z57_A-0000021.jpg  \n",
       "4     ./train_imgs/642-2-4-31-Z148_D-0000011.jpg  \n",
       "...                                          ...  \n",
       "3771  ./train_imgs/546-1-2-25-Z134_D-0000013.jpg  \n",
       "3772   ./train_imgs/186-1-1-08-Z36_E-0000023.jpg  \n",
       "3773   ./train_imgs/282-2-1-14-Z57_A-0000017.jpg  \n",
       "3774   ./train_imgs/177-1-1-07-Z36_D-0000029.jpg  \n",
       "3775   ./train_imgs/282-2-1-14-Z57_E-0000025.jpg  \n",
       "\n",
       "[3776 rows x 50 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.reset_index(drop=True, inplace=True)\n",
    "valid.reset_index(drop=True, inplace=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation Setting\n",
    "pixel_shifts = [12]\n",
    "rotation_angles = [12]\n",
    "inc_brightness_ratio = 1.2\n",
    "dec_brightness_ratio = 0.8\n",
    "noise_ratio = 0.008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 좌우 반전\n",
    "def left_right_flip(images, keypoints):\n",
    "    flipped_keypoints = []\n",
    "    flipped_images = np.flip(images, axis=1)\n",
    "    for idx, sample_keypoints in enumerate(keypoints):\n",
    "        if idx % 2 == 0:\n",
    "            flipped_keypoints.append(480.-sample_keypoints)\n",
    "        else:\n",
    "            flipped_keypoints.append(sample_keypoints)\n",
    "\n",
    "    # left_right_keypoints_convert\n",
    "    for i in range(8):\n",
    "        flipped_keypoints[2+(4*i):4+(4*i)], flipped_keypoints[4+(4*i):6+(\n",
    "            4*i)] = flipped_keypoints[4+(4*i):6+(4*i)], flipped_keypoints[2+(4*i):4+(4*i)]\n",
    "    flipped_keypoints[36:38], flipped_keypoints[38:\n",
    "                                                40] = flipped_keypoints[38:40], flipped_keypoints[36:38]\n",
    "    flipped_keypoints[44:46], flipped_keypoints[46:\n",
    "                                                48] = flipped_keypoints[46:48], flipped_keypoints[44:46]\n",
    "\n",
    "    return flipped_images, flipped_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수직/수평 동시 이동\n",
    "# forloop에서 shift_x, shift_y 중 하나만 놓으면\n",
    "# 수직 또는 수평 이동만 따로 시행 가능\n",
    "def shift_images(images, keypoints):\n",
    "    # tensor -> numpy\n",
    "    images = images.numpy()\n",
    "    shifted_images = []\n",
    "    shifted_keypoints = []\n",
    "    for shift in pixel_shifts:\n",
    "        for (shift_x, shift_y) in [(-shift, -shift), (-shift, shift), (shift, -shift), (shift, shift)]:\n",
    "            # 이동할 matrix 생성\n",
    "            M = np.float32([[1, 0, shift_x], [0, 1, shift_y]])\n",
    "            shifted_keypoint = np.array([])\n",
    "            shifted_x_list = np.array([])\n",
    "            shifted_y_list = np.array([])\n",
    "            # 이미지 이동\n",
    "            shifted_image = cv2.warpAffine(\n",
    "                images, M, (480, 270), flags=cv2.INTER_CUBIC)\n",
    "            # 이동한만큼 keypoint 수정\n",
    "            for idx, point in enumerate(keypoints):\n",
    "                if idx % 2 == 0:\n",
    "                    shifted_keypoint = np.append(\n",
    "                        shifted_keypoint, point+shift_x)\n",
    "                    shifted_x_list = np.append(shifted_x_list, point+shift_x)\n",
    "                else:\n",
    "                    shifted_keypoint = np.append(\n",
    "                        shifted_keypoint, point+shift_y)\n",
    "                    shifted_y_list = np.append(shifted_y_list, point+shift_y)\n",
    "            # 수정된 keypoint가 이미지 사이즈를 벗어나지 않으면 append\n",
    "            if np.all(0.0 < shifted_x_list) and np.all(shifted_x_list < 480) and np.all(0.0 < shifted_y_list) and np.all(shifted_y_list < 270):\n",
    "                shifted_images.append(shifted_image.reshape(270, 480, 3))\n",
    "                shifted_keypoints.append(shifted_keypoint)\n",
    "\n",
    "    return shifted_images, shifted_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 회전\n",
    "def rotate_augmentation(images, keypoints):\n",
    "    # tensor -> numpy\n",
    "    images = images.numpy()\n",
    "    rotated_images = []\n",
    "    rotated_keypoints = []\n",
    "\n",
    "    for angle in rotation_angles:\n",
    "        for angle in [angle, -angle]:\n",
    "            # 회전할 matrix 생성\n",
    "            M = cv2.getRotationMatrix2D((240, 135), angle, 1.0)\n",
    "            # cv2_imshow로는 문제없지만 추후 plt.imshow로 사진을 확인할 경우 black screen 생성...\n",
    "            # 혹시 몰라 matrix를 ndarray로 변환\n",
    "            M = np.array(M, dtype=np.float32)\n",
    "            angle_rad = -angle*pi/180\n",
    "            rotated_image = cv2.warpAffine(images, M, (480, 270))\n",
    "            rotated_images.append(rotated_image)\n",
    "\n",
    "            # keypoint를 copy하여 forloop상에서 값이 계속 없데이트 되는 것을 회피\n",
    "            rotated_keypoint = keypoints.copy()\n",
    "            rotated_keypoint[0::2] = rotated_keypoint[0::2] - 240\n",
    "            rotated_keypoint[1::2] = rotated_keypoint[1::2] - 135\n",
    "\n",
    "            for idx in range(0, len(rotated_keypoint), 2):\n",
    "                rotated_keypoint[idx] = rotated_keypoint[idx] * \\\n",
    "                    cos(angle_rad)-rotated_keypoint[idx+1]*sin(angle_rad)\n",
    "                rotated_keypoint[idx+1] = rotated_keypoint[idx] * \\\n",
    "                    sin(angle_rad)+rotated_keypoint[idx+1]*cos(angle_rad)\n",
    "\n",
    "            rotated_keypoint[0::2] = rotated_keypoint[0::2] + 240\n",
    "            rotated_keypoint[1::2] = rotated_keypoint[1::2] + 135\n",
    "            rotated_keypoints.append(rotated_keypoint)\n",
    "\n",
    "    return rotated_images, rotated_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 해상도 조절\n",
    "def alter_brightness(images):\n",
    "    altered_brightness_images = []\n",
    "    inc_brightness_images = np.clip(images*inc_brightness_ratio, 0.0, 1.0)\n",
    "    dec_brightness_images = np.clip(images*dec_brightness_ratio, 0.0, 1.0)\n",
    "    altered_brightness_images.append(inc_brightness_images)\n",
    "    altered_brightness_images.append(dec_brightness_images)\n",
    "    return altered_brightness_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random 노이즈 추가\n",
    "def add_noise(images):\n",
    "    images = images.numpy()\n",
    "    noise = noise_ratio * np.random.randn(270, 480, 3)\n",
    "    noise = noise.astype(np.float32)\n",
    "    # 생성한 noise를 원본에 add\n",
    "    noisy_image = cv2.add(images, noise)\n",
    "    return noisy_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainGenerator():\n",
    "    # 원본 이미지 resize\n",
    "    for i in range(len(train)):\n",
    "        img = tf.io.read_file(train['path'][i])  # path(경로)를 통해 이미지 읽기\n",
    "        # 경로를 통해 불러온 이미지를 tensor로 변환\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, [270, 480])   # 이미지 resize\n",
    "        img = img/255                            # 이미지 rescaling\n",
    "        target = train.iloc[:, 1:49].iloc[i, :]  # keypoint 뽑아주기\n",
    "        # image size를 1920x1080 -> 480x270으로 바꿔줬으므로 keypoint도 변경\n",
    "        target = target/4\n",
    "        \n",
    "        yield (img, target)\n",
    "\n",
    "    # horizontal flip\n",
    "    for i in range(len(train)):\n",
    "        img = tf.io.read_file(train['path'][i])\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, [270, 480])\n",
    "        img = img/255\n",
    "        target = train.iloc[:, 1:49].iloc[i, :]\n",
    "        target = target/4\n",
    "        \n",
    "        img, target = left_right_flip(img, target)        \n",
    "        \n",
    "        yield (img, target)\n",
    "\n",
    "    # Horizontal & Vertical shift\n",
    "    for i in range(len(train)):\n",
    "        img = tf.io.read_file(train['path'][i])\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, [270, 480])\n",
    "        img = img/255\n",
    "        target = train.iloc[:, 1:49].iloc[i, :]\n",
    "        target = target/4\n",
    "        \n",
    "        img_list, target_list = shift_images(img, target)\n",
    "        \n",
    "        for shifted_img, shifted_target in zip(img_list, target_list):\n",
    "            yield (shifted_img, shifted_target)\n",
    "\n",
    "    # Rotation\n",
    "    for i in range(len(train)):\n",
    "        img = tf.io.read_file(train['path'][i])\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, [270, 480])\n",
    "        img = img/255\n",
    "        target = train.iloc[:, 1:49].iloc[i, :]\n",
    "        target = target/4\n",
    "        \n",
    "        img_list, target_list = rotate_augmentation(img, target)\n",
    "        \n",
    "        for rotated_img, rotated_target in zip(img_list, target_list):\n",
    "            yield (rotated_img, rotated_target)\n",
    "\n",
    "#     # Alter_Brightness\n",
    "#     for i in range(len(train)):\n",
    "#         img = tf.io.read_file(train['path'][i])\n",
    "#         img = tf.image.decode_jpeg(img, channels=3)\n",
    "#         img = tf.image.resize(img, [270, 480])\n",
    "#         img = img/255\n",
    "#         target = train.iloc[:, 1:49].iloc[i, :]\n",
    "#         target = target/4\n",
    "        \n",
    "#         img_list = alter_brightness(img)\n",
    "        \n",
    "#         for altered_brightness_images in img_list:\n",
    "#             yield (altered_brightness_images, target)\n",
    "\n",
    "#     # Adding_Noise\n",
    "#     for i in range(len(train)):\n",
    "#         img = tf.io.read_file(train['path'][i])\n",
    "#         img = tf.image.decode_jpeg(img, channels=3)\n",
    "#         img = tf.image.resize(img, [270, 480])\n",
    "#         img = img/255\n",
    "#         target = train.iloc[:, 1:49].iloc[i, :]\n",
    "#         target = target/4\n",
    "        \n",
    "#         noisy_img = add_noise(img)\n",
    "        \n",
    "#         yield (noisy_img, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validGenerator():\n",
    "    # 원본 이미지 resize\n",
    "    for i in range(len(valid)):\n",
    "        img = tf.io.read_file(valid['path'][i])  # path(경로)를 통해 이미지 읽기\n",
    "        # 경로를 통해 불러온 이미지를 tensor로 변환\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, [270, 480])   # 이미지 resize\n",
    "        img = img/255                            # 이미지 rescaling\n",
    "        target = valid.iloc[:, 1:49].iloc[i, :]  # keypoint 뽑아주기\n",
    "        # image size를 1920x1080 -> 480x270으로 바꿔줬으므로 keypoint도 변경\n",
    "        target = target/4\n",
    "\n",
    "        yield (img, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    trainGenerator, (tf.float32, tf.float32), (tf.TensorShape([270, 480, 3]), tf.TensorShape([48])))\n",
    "train_dataset = train_dataset.batch(batch_size).prefetch(AUTOTUNE)\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_generator(\n",
    "    validGenerator, (tf.float32, tf.float32), (tf.TensorShape([270, 480, 3]), tf.TensorShape([48])))\n",
    "valid_dataset = valid_dataset.batch(batch_size).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback 설정\n",
    "earlystop = EarlyStopping(patience=10)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    factor=0.9,\n",
    "    min_lr=0,\n",
    "    verbose=1)\n",
    "\n",
    "model_check = ModelCheckpoint(  # 에포크마다 현재 가중치를 저장\n",
    "    filepath=\"./210327_aug_Xception_06_{epoch}.h5\",  # 모델 파일 경로\n",
    "    monitor='val_loss',  # val_loss 가 좋아지지 않으면 모델 파일을 덮어쓰지 않음.\n",
    "    save_best_only=True)\n",
    "\n",
    "callbacks = [earlystop, learning_rate_reduction, model_check]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Xception(input_shape=(\n",
    "   270, 480, 3), include_top=False, weights='imagenet', pooling='avg')\n",
    "\n",
    "x = base_model.output\n",
    "x = Dense(512, activation='relu', input_dim=(7*13*1536))(x)\n",
    "x = Dropout(0.1)(x)\n",
    "predictions = Dense(48)(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.01),\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 270, 480, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 134, 239, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 134, 239, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 134, 239, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 132, 237, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 132, 237, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 132, 237, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 132, 237, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 132, 237, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 132, 237, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 132, 237, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 132, 237, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 66, 119, 128) 8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 66, 119, 128) 0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 66, 119, 128) 512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 66, 119, 128) 0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 66, 119, 128) 0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 66, 119, 256) 33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 66, 119, 256) 1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 66, 119, 256) 0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 66, 119, 256) 67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 66, 119, 256) 1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 33, 60, 256)  32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 33, 60, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 33, 60, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 33, 60, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 33, 60, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 33, 60, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 33, 60, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 33, 60, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 33, 60, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 33, 60, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 17, 30, 728)  186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 17, 30, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 17, 30, 728)  2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 17, 30, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 17, 30, 728)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 17, 30, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 17, 30, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 17, 30, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 17, 30, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 17, 30, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 17, 30, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 17, 30, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 17, 30, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 17, 30, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 17, 30, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 17, 30, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 17, 30, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 17, 30, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 17, 30, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 17, 30, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 17, 30, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 17, 30, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 17, 30, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 17, 30, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 17, 30, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 17, 30, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 17, 30, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 17, 30, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 17, 30, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 17, 30, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 17, 30, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 17, 30, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 17, 30, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 17, 30, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 17, 30, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 17, 30, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 17, 30, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 17, 30, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 17, 30, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 17, 30, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 17, 30, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 17, 30, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 17, 30, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 17, 30, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 17, 30, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 17, 30, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 17, 30, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 17, 30, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 17, 30, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 17, 30, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 17, 30, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 17, 30, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 17, 30, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 17, 30, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 17, 30, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 17, 30, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 17, 30, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 17, 30, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 17, 30, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 17, 30, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 17, 30, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 17, 30, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 17, 30, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 17, 30, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 17, 30, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 17, 30, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 17, 30, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 17, 30, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 17, 30, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 17, 30, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 17, 30, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 17, 30, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 17, 30, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 17, 30, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 17, 30, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 17, 30, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 17, 30, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 17, 30, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 17, 30, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 17, 30, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 17, 30, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 17, 30, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 17, 30, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 17, 30, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 17, 30, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 17, 30, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 17, 30, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 17, 30, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 17, 30, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 17, 30, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 9, 15, 1024)  745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 9, 15, 1024)  0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 9, 15, 1024)  4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 9, 15, 1024)  0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 9, 15, 1536)  1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 9, 15, 1536)  6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 9, 15, 1536)  0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 9, 15, 2048)  3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 9, 15, 2048)  8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 9, 15, 2048)  0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          1049088     global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 48)           24624       dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,935,192\n",
      "Trainable params: 21,880,664\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./210326_aug_Xception_05_1.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3021/3021 [==============================] - 1478s 489ms/step - loss: 128.0863 - accuracy: 0.5245 - val_loss: 63.5550 - val_accuracy: 0.6563 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "3021/3021 [==============================] - 1435s 475ms/step - loss: 114.6903 - accuracy: 0.5492 - val_loss: 61.0617 - val_accuracy: 0.6611 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "3021/3021 [==============================] - 1406s 465ms/step - loss: 102.1776 - accuracy: 0.5644 - val_loss: 154.4392 - val_accuracy: 0.5322 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "3021/3021 [==============================] - 1397s 462ms/step - loss: 97.6058 - accuracy: 0.5773 - val_loss: 46.1575 - val_accuracy: 0.6516 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "3021/3021 [==============================] - 1394s 461ms/step - loss: 95.3203 - accuracy: 0.5853 - val_loss: 46.8140 - val_accuracy: 0.6205 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "3021/3021 [==============================] - 1403s 464ms/step - loss: 88.3927 - accuracy: 0.5981 - val_loss: 43.6048 - val_accuracy: 0.6348 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "3021/3021 [==============================] - 1409s 466ms/step - loss: 86.2220 - accuracy: 0.6078 - val_loss: 45.0359 - val_accuracy: 0.6611 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "3021/3021 [==============================] - 1411s 467ms/step - loss: 85.3541 - accuracy: 0.6125 - val_loss: 50.3501 - val_accuracy: 0.7064 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "3021/3021 [==============================] - 1412s 467ms/step - loss: 79.7509 - accuracy: 0.6186 - val_loss: 38.8303 - val_accuracy: 0.6778 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "3021/3021 [==============================] - 1407s 466ms/step - loss: 81.2695 - accuracy: 0.6182 - val_loss: 32.1039 - val_accuracy: 0.7112 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "3021/3021 [==============================] - 1403s 465ms/step - loss: 76.0159 - accuracy: 0.6287 - val_loss: 33.1001 - val_accuracy: 0.6754 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "3021/3021 [==============================] - 1405s 465ms/step - loss: 74.3023 - accuracy: 0.6365 - val_loss: 36.2610 - val_accuracy: 0.7064 - lr: 0.0100\n",
      "Epoch 13/100\n",
      "3021/3021 [==============================] - 1405s 465ms/step - loss: 72.8052 - accuracy: 0.6390 - val_loss: 32.1962 - val_accuracy: 0.7160 - lr: 0.0100\n",
      "Epoch 14/100\n",
      "3021/3021 [==============================] - 1399s 463ms/step - loss: 70.6261 - accuracy: 0.6461 - val_loss: 29.1731 - val_accuracy: 0.7279 - lr: 0.0100\n",
      "Epoch 15/100\n",
      "3021/3021 [==============================] - 1375s 455ms/step - loss: 68.3869 - accuracy: 0.6536 - val_loss: 32.8125 - val_accuracy: 0.7327 - lr: 0.0100\n",
      "Epoch 16/100\n",
      "3021/3021 [==============================] - 1370s 453ms/step - loss: 67.2819 - accuracy: 0.6576 - val_loss: 32.2681 - val_accuracy: 0.7160 - lr: 0.0100\n",
      "Epoch 17/100\n",
      "3021/3021 [==============================] - 1361s 450ms/step - loss: 66.3173 - accuracy: 0.6598 - val_loss: 40.5941 - val_accuracy: 0.7017 - lr: 0.0100\n",
      "Epoch 18/100\n",
      "3021/3021 [==============================] - 1365s 452ms/step - loss: 65.3147 - accuracy: 0.6621 - val_loss: 32.3640 - val_accuracy: 0.7685 - lr: 0.0100\n",
      "Epoch 19/100\n",
      "3021/3021 [==============================] - 1360s 450ms/step - loss: 64.0668 - accuracy: 0.6672 - val_loss: 27.4265 - val_accuracy: 0.7661 - lr: 0.0100\n",
      "Epoch 20/100\n",
      "3021/3021 [==============================] - 1364s 451ms/step - loss: 62.2076 - accuracy: 0.6664 - val_loss: 32.0515 - val_accuracy: 0.7470 - lr: 0.0100\n",
      "Epoch 21/100\n",
      "3021/3021 [==============================] - 1393s 461ms/step - loss: 61.2351 - accuracy: 0.6724 - val_loss: 31.7860 - val_accuracy: 0.7446 - lr: 0.0100\n",
      "Epoch 22/100\n",
      "3021/3021 [==============================] - 1401s 464ms/step - loss: 60.9378 - accuracy: 0.6743 - val_loss: 35.5105 - val_accuracy: 0.7327 - lr: 0.0100\n",
      "Epoch 23/100\n",
      "3021/3021 [==============================] - 1425s 472ms/step - loss: 59.9969 - accuracy: 0.6712 - val_loss: 28.4543 - val_accuracy: 0.7661 - lr: 0.0100\n",
      "Epoch 24/100\n",
      "3021/3021 [==============================] - 1402s 464ms/step - loss: 59.2838 - accuracy: 0.6754 - val_loss: 26.9163 - val_accuracy: 0.7470 - lr: 0.0100\n",
      "Epoch 25/100\n",
      "3021/3021 [==============================] - 1374s 455ms/step - loss: 58.2267 - accuracy: 0.6727 - val_loss: 30.9159 - val_accuracy: 0.7518 - lr: 0.0100\n",
      "Epoch 26/100\n",
      "3021/3021 [==============================] - 1439s 476ms/step - loss: 57.8645 - accuracy: 0.6806 - val_loss: 30.4064 - val_accuracy: 0.7542 - lr: 0.0100\n",
      "Epoch 27/100\n",
      "3021/3021 [==============================] - 1505s 498ms/step - loss: 55.7789 - accuracy: 0.6835 - val_loss: 23.4577 - val_accuracy: 0.7733 - lr: 0.0100\n",
      "Epoch 28/100\n",
      "3021/3021 [==============================] - 1494s 495ms/step - loss: 55.7837 - accuracy: 0.6851 - val_loss: 24.9634 - val_accuracy: 0.7279 - lr: 0.0100\n",
      "Epoch 29/100\n",
      "3021/3021 [==============================] - 1496s 495ms/step - loss: 56.5693 - accuracy: 0.6872 - val_loss: 23.8579 - val_accuracy: 0.7399 - lr: 0.0100\n",
      "Epoch 30/100\n",
      "3021/3021 [==============================] - 1494s 495ms/step - loss: 53.2169 - accuracy: 0.6943 - val_loss: 25.3626 - val_accuracy: 0.7924 - lr: 0.0100\n",
      "Epoch 31/100\n",
      "3021/3021 [==============================] - 1496s 495ms/step - loss: 53.6285 - accuracy: 0.6862 - val_loss: 23.0614 - val_accuracy: 0.7446 - lr: 0.0100\n",
      "Epoch 32/100\n",
      "3021/3021 [==============================] - 1499s 496ms/step - loss: 53.4377 - accuracy: 0.6867 - val_loss: 25.5219 - val_accuracy: 0.7613 - lr: 0.0100\n",
      "Epoch 33/100\n",
      "3021/3021 [==============================] - 1498s 496ms/step - loss: 56.4973 - accuracy: 0.6808 - val_loss: 28.6110 - val_accuracy: 0.7685 - lr: 0.0100\n",
      "Epoch 34/100\n",
      "3021/3021 [==============================] - 1497s 496ms/step - loss: 51.6503 - accuracy: 0.6890 - val_loss: 25.1845 - val_accuracy: 0.7446 - lr: 0.0100\n",
      "Epoch 35/100\n",
      "3021/3021 [==============================] - 1500s 497ms/step - loss: 51.4215 - accuracy: 0.6923 - val_loss: 22.1216 - val_accuracy: 0.7804 - lr: 0.0100\n",
      "Epoch 36/100\n",
      "3021/3021 [==============================] - 1498s 496ms/step - loss: 50.5420 - accuracy: 0.6942 - val_loss: 26.8933 - val_accuracy: 0.7780 - lr: 0.0100\n",
      "Epoch 37/100\n",
      "3021/3021 [==============================] - 1498s 496ms/step - loss: 50.8140 - accuracy: 0.6968 - val_loss: 25.9617 - val_accuracy: 0.7685 - lr: 0.0100\n",
      "Epoch 38/100\n",
      "3021/3021 [==============================] - 1496s 495ms/step - loss: 51.2991 - accuracy: 0.6957 - val_loss: 25.5043 - val_accuracy: 0.7685 - lr: 0.0100\n",
      "Epoch 39/100\n",
      "3021/3021 [==============================] - 1496s 495ms/step - loss: 50.0484 - accuracy: 0.6930 - val_loss: 26.0844 - val_accuracy: 0.7757 - lr: 0.0100\n",
      "Epoch 40/100\n",
      "3021/3021 [==============================] - 1496s 495ms/step - loss: 48.2926 - accuracy: 0.6989 - val_loss: 25.4396 - val_accuracy: 0.7589 - lr: 0.0100\n",
      "Epoch 41/100\n",
      "3021/3021 [==============================] - 1494s 495ms/step - loss: 47.4800 - accuracy: 0.6986 - val_loss: 28.0325 - val_accuracy: 0.7613 - lr: 0.0100\n",
      "Epoch 42/100\n",
      "3021/3021 [==============================] - 1497s 495ms/step - loss: 48.0730 - accuracy: 0.6999 - val_loss: 27.3336 - val_accuracy: 0.7804 - lr: 0.0100\n",
      "Epoch 43/100\n",
      "3021/3021 [==============================] - 1496s 495ms/step - loss: 47.2137 - accuracy: 0.6972 - val_loss: 22.6182 - val_accuracy: 0.7804 - lr: 0.0100\n",
      "Epoch 44/100\n",
      "3021/3021 [==============================] - 1497s 496ms/step - loss: 46.2570 - accuracy: 0.7029 - val_loss: 24.5722 - val_accuracy: 0.7637 - lr: 0.0100\n",
      "Epoch 45/100\n",
      "3021/3021 [==============================] - ETA: 0s - loss: 48.5405 - accuracy: 0.6985\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.008999999798834325.\n",
      "3021/3021 [==============================] - 1496s 495ms/step - loss: 48.5405 - accuracy: 0.6985 - val_loss: 25.3125 - val_accuracy: 0.7733 - lr: 0.0100\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=100,\n",
    "    validation_data=valid_dataset,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
